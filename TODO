DONE

	Hook up the ip2location to the new server 5 backend via handler -> state

	Disable google pubsub by default. Enable with an env var.

	Disable google bigquery by default. Enable with an env var.

	Got the raspberry pi server initing with the server backend 5 in dev.

	Got the raspberry pi client connecting to the raspberry pi server and upgrading.

	Session data bytes was desynced with raspberry. Was 500 bytes, but now 1024.

	Extend magic values to have a sequence

	If the sequence is <= current sequence, hold the current magic values.

	This will stop occasionally going back in time to a previous value, if a magic backend instance is slightly delayed.

	Enable debug logs in dev.

	Now deploy to dev and make sure that the magic values stop flapping.

	Fix confirmed.

	Now we need to debug why there are no next routes. Is it the route matrix in dev, or is it the near relays?

	To debug, extend the routing functions in core.go to write out a summary of the number of routable relays when deciding if they take network next, and whether to continue network next.

	This way we can see: "0/9 source relays are routable"

	and go, oh, no near relays are routable.

	or. "0/0 source relays are routable" -- oh, there are no near relays.. why?

	etc...

	It's not the near relays:

		6/9 source relays are routable

	It has to be the route matrix then. Most likely, the max jitter is set too low on the relay backend, so the route matrix can't route into the dest relay.

TODO
	
	The next thing to do now is to inspect the route matrix.

	This can be done via the next tool.

	Write some new code to actually print out the route matrix as CSV, so I can import it into a spreadsheet...

	---------------

	If the default server backend port in sdk5 is 45000, then we need to run the server backend on that port.

	export NEXT_SERVER_BACKEND_PORT=40000

	Alternatively, we drop back to server backend 5 being 40000. which is fine IMO.

	---------------























	-----------------

	Implement a new portal cruncher based around the service.go

	-----------------

	Extend server backend to write session update data messages to redis pubsub.

	-----------------

	Run the portal cruncher in the happy path and verify it gets the redis pubsub messages.

	-----------------

	Update the old database code to stash the "Latitude" and "Longitude" for datacenters in the parent struct, so it is compatible with the new database code.

	-----------------

	Implement func tests for each major service, especially around leader election and transfer in-situ

	-----------------

	We need to check the crypto signature on relay updates.

	-----------------












































    -----------------

    After this, it is time to plumb session update messages to analytics, then process them to perform insertion into bigquery.

    -----------------

    Once this is done, we basically have a working SDK5 backend in dev.

    -----------------

    The next step then is to setup a build process for relays in semaphore.

    -----------------

    Then extend the relay to have the concept of a "secondary" backend, which it will send relay updates to, but it will not shut down if it can't communicate with.

    -----------------

    Once this is done we can create a new prod5 environment, and set up a few relays in prod so that they use prod5 as secondary relay backend.

    -----------------

    Once this is verified stable, upgrade all relays so they report to the secondary prod5 relay backend.

    -----------------


































    -----------------

	analytics service is spamming this in dev:

		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping

	Why can't it read the cost_matrix_stats message?

	-----------------

	analytics is failing to insert into bigquery in dev:

		Jan 04 04:29:18 analytics-mig-hkq3 app[4833]: error: failed to publish bigquery entry: 244 row insertions failed (insertion of row [insertID: "9blW809c4pZF2Tre0gkTFV5UKaI"; insertIndex: 0] failed with error: {Location: "numRelays"; Message: "no such field: numRelays."; Reason: "invalid"}, insertion of row [insertID: "IFxlFo9QjZskGR38a35pHJAoItl"; insertIndex: 1] failed with error: {Location: "numDatacenters"; Message: "no such field: numDatacenters."; Reason: "invalid"}, insertion of row [insertID: "27d1wczpzBolHFsuiwfOsUdax04"; insertIndex: 2] failed with error: {Location: "numDatacenters"; Message: "no such field: numDatacenters."; Reason: "invalid"}, ...)
		Jan 04 04:29:18 analytics-mig-hkq3 app[4833]: error: failed to publish bigquery entry: 245 row insertions failed (insertion of row [insertID: "fqcpRXzcepXDie22eUl57AyUZV8"; insertIndex: 0] failed with error: {Location: "bytes"; Message: "no such field: bytes."; Reason: "invalid"}, insertion of row [insertID: "ce23BHskKZVXVQ8U0mlDfROp5Re"; insertIndex: 1] failed with error: {Location: "numRelays"; Message: "no such field: numRelays."; Reason: "invalid"}, insertion of row [insertID: "WH8doSUiENSPxzdIxjMnA04Jq6U"; insertIndex: 2] failed with error: {Location: "numRelays"; Message: "no such field: numRelays."; Reason: "invalid"}, ...)

	-----------------
