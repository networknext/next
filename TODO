DONE

	Update the SDK only to perform pings on slice 1.

	Make sure near relay pings a cleared, so if I choose to send down a new set of near relays to ping mid-session, the previous near relay pings won't affect it.

	Verify that happy path is still rockin'

	Remove "committed" concept from sdk5 backend

	Remove "committed" concept from sdk5 next.cpp -- we just don't need the complexity.

	Add a unit test to specifically verify that we don't send near relays down on slice 2.

	Low frequency pings 10 packets per-second.

	High frequency pings can be 60 packets per-second :)

TODO

	Fix heisenbug in route tokens in session update tests

	----------

	Extend SDK to pass up actual bandwidth used for direct as well.

	Without this, we can't get an estimate of bandwidth use while in analysis only mode, which makes customer trials difficult.

	----------

	What else is really annoying about the SDK that I should take this time to address?

	----------

































































	-----------------

	Test session update response packet write in post, with session data as well.

	-----------------

	Implement code to fill and pass session update data to portal

	-----------------

	Hook up the ip2location to the new server 5 backend

	-----------------

	Hook up the old database code to write datacenter lat/long to the place expected by the new database code.

	-----------------

	Check over all // todo and make sure we are good.

	-----------------

	Implement func tests for each major service, especially around leader election and transfer in-situ

	-----------------











































	-----------------

	Need some raspberry pi like service so we have some real clients in dev.

	Setup a test customer "Raspberry" and use the existing raspberry code or pro tool to create this sort of "multi-client".

	This way I can easily run multiple clients pointing at dev from dr strange, and they are easily accessible.

	Run the raspberry pi server inside the linode instance...

    -----------------

    Once this is working, verify the raspberry pi clients are taking sessions via "next relays" in dev.

    -----------------

    Then the next step is to extend the session handler so it posts portal data to the portal crunchers

    -----------------

    Then the portal crunchers should be cleaned up so that they use the service.go framework and setup as an autoscale mig.

    -----------------

    After this, it is time to plumb session update messages to analytics, then process them to perform insertion into bigquery.

    -----------------

    Once this is done, we basically have a working SDK5 backend in dev.

    -----------------

    The next step then is to setup a build process for relays in semaphore.

    -----------------

    Then extend the relay to have the concept of a "secondary" backend, which it will send relay updates to, but it will not shut down if it can't communicate with.

    -----------------

    Once this is done we can create a new prod5 environment, and set up a few relays in prod so that they use prod5 as secondary relay backend.

    -----------------

    Once this is verified stable, upgrade all relays so they report to the secondary prod5 relay backend.

    -----------------


































    -----------------

    Google pubsub should be disabled by default, and enabled explicitly with env var

		[2023-01-04 12:13:33] error: failed to send message batch: rpc error: code = NotFound desc = Resource not found (resource=route_matrix_stats).
		[2023-01-04 12:13:33] error: failed to send message batch: rpc error: code = NotFound desc = Resource not found (resource=route_matrix_stats).
		[2023-01-04 12:13:33] error: failed to send message batch: rpc error: code = NotFound desc = Resource not found (resource=cost_matrix_stats).

	-----------------

	Google bigquery should be disabled by default, and enabled explicitly with env var.

	-----------------

	analytics service is spamming this in dev:

		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping
		Jan 04 03:38:30 analytics-mig-hkq3 app[4831]: error: could not read cost_matrix_stats message - dropping

	Why can't it read the cost_matrix_stats message?

	-----------------

	analytics is failing to insert into bigquery in dev:

		Jan 04 04:29:18 analytics-mig-hkq3 app[4833]: error: failed to publish bigquery entry: 244 row insertions failed (insertion of row [insertID: "9blW809c4pZF2Tre0gkTFV5UKaI"; insertIndex: 0] failed with error: {Location: "numRelays"; Message: "no such field: numRelays."; Reason: "invalid"}, insertion of row [insertID: "IFxlFo9QjZskGR38a35pHJAoItl"; insertIndex: 1] failed with error: {Location: "numDatacenters"; Message: "no such field: numDatacenters."; Reason: "invalid"}, insertion of row [insertID: "27d1wczpzBolHFsuiwfOsUdax04"; insertIndex: 2] failed with error: {Location: "numDatacenters"; Message: "no such field: numDatacenters."; Reason: "invalid"}, ...)
		Jan 04 04:29:18 analytics-mig-hkq3 app[4833]: error: failed to publish bigquery entry: 245 row insertions failed (insertion of row [insertID: "fqcpRXzcepXDie22eUl57AyUZV8"; insertIndex: 0] failed with error: {Location: "bytes"; Message: "no such field: bytes."; Reason: "invalid"}, insertion of row [insertID: "ce23BHskKZVXVQ8U0mlDfROp5Re"; insertIndex: 1] failed with error: {Location: "numRelays"; Message: "no such field: numRelays."; Reason: "invalid"}, insertion of row [insertID: "WH8doSUiENSPxzdIxjMnA04Jq6U"; insertIndex: 2] failed with error: {Location: "numRelays"; Message: "no such field: numRelays."; Reason: "invalid"}, ...)

	-----------------
